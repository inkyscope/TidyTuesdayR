---
title: "nycrestaurant_inspection"
author: "sung inkyung"
date: '2019 7 10 '
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
### source:https://www.tidytextmining.com/ngrams.html,
### source:https://github.com/dgrtwo/data-screencasts/blob/master/nyc-restaurants.Rmd

```{r}
library(tidyverse)
library(lubridate)
library(janitor)
library(cowplot)
```

```{r}
restaurant_inspections_raw <- read_csv("https://data.cityofnewyork.us/api/views/43nn-pn8j/rows.csv")
```

```{r}
restaurant_inspections <- restaurant_inspections_raw %>% 
  janitor::clean_names() %>%
  select(-phone, -record_date, -building, -street) %>%
  mutate(inspection_date = mdy(inspection_date)) %>%
  separate(inspection_type, c("inspection_program", "inspection_type"), sep = " / ")
```

```{r}
restaurant_inspections %>% 
  count(cuisine_description, violation_description, sort = TRUE)

restaurant_inspections %>% 
  count(year = year(inspection_date))
```

```{r}
restaurant_inspections %>% 
  count(violation_description, sort = TRUE) %>% 
  head() %>% 
  pull(violation_description)
```

```{r}
restaurant_inspections %>%  
  group_by(cuisine_description) %>% 
  summarise(avg_score = mean(score),
            median_score = median(score),
            restaurants = n()) %>% 
  arrange(desc(restaurants))
```

```{r}
library(tidytext)
library(widyr)
library(ggraph)
library(igraph)
```

```{r}
violations_bigram <- restaurant_inspections %>%
  filter(!is.na(violation_description)) %>% 
  select(-action, -zipcode, -violation_code, -grade_date) %>%   unnest_tokens(bigram, violation_description, token = "ngrams", n = 2) %>% 
  filter(str_detect(bigram, "[a-z]")) %>% 
  count(bigram, sort = TRUE) 
  
violations_bigram
```

```{r}
bigrams_separated <- violations_bigram %>%
  separate(bigram, c("word1", "word2"), sep = " ") 

bigrams_filtered <- bigrams_separated %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word) %>% 
  filter(str_detect(word1, "[a-z]"))

# new bigram counts:
bigram_counts <- bigrams_filtered %>% 
  count(word1, word2, sort = TRUE)

bigram_counts
```

```{r}
bigrams_separated %>% 
  filter(word1 == "not") %>% 
  count(word1, word2, sort = TRUE)
```

```{r}
AFINN <- get_sentiments("afinn")

AFINN
```

```{r}
not_words <- bigrams_separated %>%
  filter(word1 == "not") %>%
  inner_join(AFINN, by = c(word2 = "word")) %>%
  count(word2, score, sort = TRUE)

not_words
```

```{r}
not_words %>%
  mutate(contribution = n * score) %>%
  arrange(desc(abs(contribution))) %>%
  head(6) %>%
  mutate(word2 = reorder(word2, contribution)) %>%
  ggplot(aes(word2, n * score, fill = n * score > 0)) +
  geom_col(show.legend = FALSE) +
  scale_fill_manual(values = c("#f15e75", "#27c96d")) +
  xlab("Words preceded by \"not\"") +
  ylab("Sentiment score * number of occurrences") +
  coord_flip() +
  theme_minimal()
```

```{r}
violations_words <- restaurant_inspections %>% 
  unnest_tokens(word, violation_description) %>%
  filter(!word %in% stop_words$word,
         str_detect(word, "[a-z]")) %>% 
  count(word, sort = TRUE) %>% 
  mutate(word = fct_reorder(word, n)) %>% 
  head(20) %>% 
  ggplot(aes(word, n))+
  geom_col(fill = "#f15e75") +
  coord_flip() +
  labs(title = "Common words in violations inspection of NY restaurants") +
  theme_minimal_vgrid()
```

```{r}
violations_words_count <-  violations_words %>% 
  pairwise_count(word, camis, sort = TRUE) %>% 
  filter(n > 10000)

violations_words_count
```

```{r}
violations_words_count %>% 
  filter(item1 == "properly")

violations_words_count %>% 
  filter(item1 == "unacceptable") %>% 
  filter(n >100)
```

```{r}
violations_graph <-  violations_words_count %>% 
  filter(n > 1000) %>% 
  graph_from_data_frame()

violations_graph
```

```{r}
set.seed(2019)

violations_graph %>% 
  ggraph(layout = "fr")+
  geom_edge_link()+
  geom_node_point(size = 5)+
  geom_node_text(aes(label = name), vjust = 1, hjust =1)+
  theme_void()
```

```{r}
set.seed(2019)

a <- grid::arrow(type = "closed", length = unit(.15, "inches"))

ggraph(violations_graph, layout = "graphopt") +
  geom_edge_link(aes(edge_alpha = n), 
                 show.legend = FALSE,
                 arrow = a, end_cap = circle(.07, 'inches')) +
  geom_node_point(color = "#008080", size = 5) +
  geom_node_text(aes(label = name, color = "#940a0a"), 
                 vjust = 1, 
                 hjust = 1) +
  theme_void()+
  theme(legend.text = element_blank(),
        legend.title = element_blank())
```

```{r}
# word correlations
violations_words_cors <-  violations_words %>% 
  pairwise_cor(word, camis, sort = TRUE) 

violations_words_cors
```

```{r}
violations_words_cors %>% 
  filter(item1 == "properly") %>% 
  filter(correlation > 0.6)

violations_words_cors %>% 
  filter(item1 == "unacceptable") %>% 
   filter(correlation > 0.6)
```

```{r}
violations_words_cors %>%
  filter(item1 %in% c("improperly", "unacceptable", "excessive", "harmful")) %>%
  group_by(item1) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(item2 = reorder(item2, correlation)) %>%
  ggplot(aes(item2, correlation)) +
  geom_bar(stat = "identity") +
  facet_wrap(~ item1, scales = "free") +
  coord_flip()
```

````{r}
set.seed(2019)

violations_words_cors %>%
  filter(item1 %in% c("improperly", "unacceptable", "excessive", "harmful")) %>%
  group_by(item1) %>%
  top_n(30) %>%
  ungroup() %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = correlation), 
                 show.legend = FALSE) +
  geom_node_point(color = "#f15e75", size = 3) +
  geom_node_text(aes(label = name), repel = TRUE) +
  theme_void()
```

```{r}
set.seed(2019)

violations_words_cors %>%
  filter(item1 %in% c("improperly", "unacceptable", "excessive", "harmful")) %>%
  group_by(item1) %>%
  top_n(30) %>%
  ungroup() %>%
  graph_from_data_frame() %>%
  ggraph(layout = "graphopt") +
  geom_edge_link(aes(edge_alpha = correlation), 
                 show.legend = FALSE) +
  geom_node_point(color = "#f15e75", size = 3) +
  geom_node_text(aes(label = name), repel = TRUE) +
  theme_void()
```